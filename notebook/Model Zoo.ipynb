{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.preparation import fetch_dataset\n",
    "from src.modules.visualizer import do_heatmap\n",
    "dataset = fetch_dataset('dataset_all_slim.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>LabelVector</th>\n",
       "      <th>Begin</th>\n",
       "      <th>End</th>\n",
       "      <th>Sample</th>\n",
       "      <th>CEPST</th>\n",
       "      <th>SPECT</th>\n",
       "      <th>MFCC</th>\n",
       "      <th>CWT</th>\n",
       "      <th>ZCR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rec2018-02-02_01h34m08.386s.wav</td>\n",
       "      <td>Noise</td>\n",
       "      <td>52279</td>\n",
       "      <td>58753</td>\n",
       "      <td>[[-79, -63, -30, 6, 14, 23, 27, 18, 17, 10, -1...</td>\n",
       "      <td>[[[1.693221, 1.775855, 1.741249, 1.616202, 2.1...</td>\n",
       "      <td>[[[0.011621, 0.010184, 0.011724, 0.015311, 0.0...</td>\n",
       "      <td>[[[-18.136064, -15.67883, -13.065683, -11.4263...</td>\n",
       "      <td>[[[0.196308, 0.210414, 0.217209, 0.187533, 0.1...</td>\n",
       "      <td>[[0.976517, 0.988258, 0.972603, 0.95499, 0.951...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rec2018-02-02_01h34m08.386s.wav</td>\n",
       "      <td>Noise</td>\n",
       "      <td>44530</td>\n",
       "      <td>52412</td>\n",
       "      <td>[[-3, 3, 4, 10, 7, 4, -1, -14, -8, 7, 2, -5, -...</td>\n",
       "      <td>[[[2.140195, 1.835786, 1.860486, 1.820666, 1.7...</td>\n",
       "      <td>[[[0.006132, 0.004942, 0.003436, 0.005528, 0.0...</td>\n",
       "      <td>[[[-3.256531, -4.392584, -5.202826, -5.233054,...</td>\n",
       "      <td>[[[0.072738, 0.071596, 0.071802, 0.073953, 0.0...</td>\n",
       "      <td>[[0.8591, 0.835616, 0.833659, 0.841487, 0.8767...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec2018-02-02_01h34m08.386s.wav</td>\n",
       "      <td>Noise</td>\n",
       "      <td>2670</td>\n",
       "      <td>8888</td>\n",
       "      <td>[[-138, -164, -105, 29, 144, 172, 240, 182, 46...</td>\n",
       "      <td>[[[1.076635, 1.698971, 2.232763, 1.433347, 0.6...</td>\n",
       "      <td>[[[0.01812, 0.00675, 0.00852, 0.014756, 0.0331...</td>\n",
       "      <td>[[[-11.771419, -14.452424, -20.437652, -27.309...</td>\n",
       "      <td>[[[0.678713, 0.447045, 0.399548, 0.39986, 0.57...</td>\n",
       "      <td>[[0.992172, 0.992172, 0.992172, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rec2018-02-02_01h34m08.386s.wav</td>\n",
       "      <td>Noise</td>\n",
       "      <td>15018</td>\n",
       "      <td>25089</td>\n",
       "      <td>[[-6, -12, -8, -1, -6, 7, 19, 16, 4, 2, 13, 11...</td>\n",
       "      <td>[[[1.609493, 1.033311, 1.006966, 1.05215, 0.83...</td>\n",
       "      <td>[[[0.014096, 0.018861, 0.024633, 0.011562, 0.0...</td>\n",
       "      <td>[[[-22.452866, -24.279197, -23.800461, -22.455...</td>\n",
       "      <td>[[[0.105505, 0.156634, 0.183518, 0.18604, 0.18...</td>\n",
       "      <td>[[0.988258, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rec2018-01-23_10h59m20.895s.wav</td>\n",
       "      <td>Exhale</td>\n",
       "      <td>3454</td>\n",
       "      <td>15745</td>\n",
       "      <td>[[194, 117, 14, -74, -118, -167, -190, -102, 3...</td>\n",
       "      <td>[[[1.643628, 0.942107, 0.530973, 0.273131, 0.2...</td>\n",
       "      <td>[[[0.011266, 0.015878, 0.025697, 0.043823, 0.0...</td>\n",
       "      <td>[[[-33.276069, -29.523152, -27.258144, -27.167...</td>\n",
       "      <td>[[[0.192724, 0.851869, 2.405978, 5.085328, 7.8...</td>\n",
       "      <td>[[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Filename LabelVector  Begin    End  \\\n",
       "0  rec2018-02-02_01h34m08.386s.wav       Noise  52279  58753   \n",
       "1  rec2018-02-02_01h34m08.386s.wav       Noise  44530  52412   \n",
       "2  rec2018-02-02_01h34m08.386s.wav       Noise   2670   8888   \n",
       "3  rec2018-02-02_01h34m08.386s.wav       Noise  15018  25089   \n",
       "4  rec2018-01-23_10h59m20.895s.wav      Exhale   3454  15745   \n",
       "\n",
       "                                              Sample  \\\n",
       "0  [[-79, -63, -30, 6, 14, 23, 27, 18, 17, 10, -1...   \n",
       "1  [[-3, 3, 4, 10, 7, 4, -1, -14, -8, 7, 2, -5, -...   \n",
       "2  [[-138, -164, -105, 29, 144, 172, 240, 182, 46...   \n",
       "3  [[-6, -12, -8, -1, -6, 7, 19, 16, 4, 2, 13, 11...   \n",
       "4  [[194, 117, 14, -74, -118, -167, -190, -102, 3...   \n",
       "\n",
       "                                               CEPST  \\\n",
       "0  [[[1.693221, 1.775855, 1.741249, 1.616202, 2.1...   \n",
       "1  [[[2.140195, 1.835786, 1.860486, 1.820666, 1.7...   \n",
       "2  [[[1.076635, 1.698971, 2.232763, 1.433347, 0.6...   \n",
       "3  [[[1.609493, 1.033311, 1.006966, 1.05215, 0.83...   \n",
       "4  [[[1.643628, 0.942107, 0.530973, 0.273131, 0.2...   \n",
       "\n",
       "                                               SPECT  \\\n",
       "0  [[[0.011621, 0.010184, 0.011724, 0.015311, 0.0...   \n",
       "1  [[[0.006132, 0.004942, 0.003436, 0.005528, 0.0...   \n",
       "2  [[[0.01812, 0.00675, 0.00852, 0.014756, 0.0331...   \n",
       "3  [[[0.014096, 0.018861, 0.024633, 0.011562, 0.0...   \n",
       "4  [[[0.011266, 0.015878, 0.025697, 0.043823, 0.0...   \n",
       "\n",
       "                                                MFCC  \\\n",
       "0  [[[-18.136064, -15.67883, -13.065683, -11.4263...   \n",
       "1  [[[-3.256531, -4.392584, -5.202826, -5.233054,...   \n",
       "2  [[[-11.771419, -14.452424, -20.437652, -27.309...   \n",
       "3  [[[-22.452866, -24.279197, -23.800461, -22.455...   \n",
       "4  [[[-33.276069, -29.523152, -27.258144, -27.167...   \n",
       "\n",
       "                                                 CWT  \\\n",
       "0  [[[0.196308, 0.210414, 0.217209, 0.187533, 0.1...   \n",
       "1  [[[0.072738, 0.071596, 0.071802, 0.073953, 0.0...   \n",
       "2  [[[0.678713, 0.447045, 0.399548, 0.39986, 0.57...   \n",
       "3  [[[0.105505, 0.156634, 0.183518, 0.18604, 0.18...   \n",
       "4  [[[0.192724, 0.851869, 2.405978, 5.085328, 7.8...   \n",
       "\n",
       "                                                 ZCR  \n",
       "0  [[0.976517, 0.988258, 0.972603, 0.95499, 0.951...  \n",
       "1  [[0.8591, 0.835616, 0.833659, 0.841487, 0.8767...  \n",
       "2  [[0.992172, 0.992172, 0.992172, 1.0, 1.0, 1.0,...  \n",
       "3  [[0.988258, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  \n",
       "4  [[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.python.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the size of the window that is fed into the DNN\n",
    "window_size = 15\n",
    "# The number of the features present in the dataset\n",
    "num_of_features = 42\n",
    "# Number of distinct labels in the output\n",
    "label_length = 4\n",
    "# Hyperparameter that defines the number of samples to work through\n",
    "# before updating the internal model parameters.\n",
    "batch_size = 25\n",
    "# Epochs\n",
    "ep = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=False, input_shape=(window_size, num_of_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(label_length, activation='softmax'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                   optimizer='rmsprop',\n",
    "                   metrics=['accuracy',])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.processing import make_tf_dataset, split_train_test\n",
    "\n",
    "df_train, df_test = split_train_test(dataset= dataset, percentage= 0.8)\n",
    "\n",
    "data_train = make_tf_dataset(df_train, window_size, num_of_features, label_length ).batch(batch_size)\n",
    "data_test = make_tf_dataset(df_test ,window_size, num_of_features, label_length).batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(927, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(231, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2623/2623 [==============================] - 80s 31ms/step - loss: 0.1000 - accuracy: 0.9696\n",
      "Epoch 2/100\n",
      "2623/2623 [==============================] - 77s 29ms/step - loss: 0.0993 - accuracy: 0.9706\n",
      "Epoch 3/100\n",
      "2623/2623 [==============================] - 77s 29ms/step - loss: 0.0993 - accuracy: 0.9705\n",
      "Epoch 4/100\n",
      "2623/2623 [==============================] - 77s 29ms/step - loss: 0.1017 - accuracy: 0.9704\n",
      "Epoch 5/100\n",
      "2623/2623 [==============================] - 77s 29ms/step - loss: 0.0989 - accuracy: 0.9711\n",
      "Epoch 6/100\n",
      "2623/2623 [==============================] - 77s 29ms/step - loss: 0.1007 - accuracy: 0.9706\n",
      "Epoch 7/100\n",
      "2623/2623 [==============================] - 78s 30ms/step - loss: 0.0979 - accuracy: 0.9719\n",
      "Epoch 8/100\n",
      "2623/2623 [==============================] - 79s 30ms/step - loss: 0.0959 - accuracy: 0.9725\n",
      "Epoch 9/100\n",
      "2623/2623 [==============================] - 83s 32ms/step - loss: 0.0964 - accuracy: 0.9722\n",
      "Epoch 10/100\n",
      "2623/2623 [==============================] - 85s 32ms/step - loss: 0.1000 - accuracy: 0.9713\n",
      "Epoch 11/100\n",
      "2623/2623 [==============================] - 86s 33ms/step - loss: 0.1000 - accuracy: 0.9717\n",
      "Epoch 12/100\n",
      "2623/2623 [==============================] - 85s 32ms/step - loss: 0.0981 - accuracy: 0.9724\n",
      "Epoch 13/100\n",
      "2623/2623 [==============================] - 86s 33ms/step - loss: 0.0966 - accuracy: 0.9728\n",
      "Epoch 14/100\n",
      "2623/2623 [==============================] - 86s 33ms/step - loss: 0.0947 - accuracy: 0.9724\n",
      "Epoch 15/100\n",
      "2623/2623 [==============================] - 84s 32ms/step - loss: 0.0945 - accuracy: 0.9730\n",
      "Epoch 16/100\n",
      "2623/2623 [==============================] - 84s 32ms/step - loss: 0.0998 - accuracy: 0.9724\n",
      "Epoch 17/100\n",
      "2623/2623 [==============================] - 85s 32ms/step - loss: 0.0985 - accuracy: 0.9722\n",
      "Epoch 18/100\n",
      "2623/2623 [==============================] - 85s 32ms/step - loss: 0.0970 - accuracy: 0.9730\n",
      "Epoch 19/100\n",
      "2623/2623 [==============================] - 85s 32ms/step - loss: 0.0964 - accuracy: 0.9721\n",
      "Epoch 20/100\n",
      "2623/2623 [==============================] - 84s 32ms/step - loss: 0.0931 - accuracy: 0.9739\n",
      "Epoch 21/100\n",
      "2623/2623 [==============================] - 85s 32ms/step - loss: 0.1014 - accuracy: 0.9727\n",
      "Epoch 22/100\n",
      "2623/2623 [==============================] - 85s 32ms/step - loss: 0.0979 - accuracy: 0.9734\n",
      "Epoch 23/100\n",
      "2623/2623 [==============================] - 75s 29ms/step - loss: 0.0994 - accuracy: 0.9733\n",
      "Epoch 24/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.1006 - accuracy: 0.9732\n",
      "Epoch 25/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0922 - accuracy: 0.9750\n",
      "Epoch 26/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0963 - accuracy: 0.9741\n",
      "Epoch 27/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0977 - accuracy: 0.9737\n",
      "Epoch 28/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.1007 - accuracy: 0.9737\n",
      "Epoch 29/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.1013 - accuracy: 0.9732\n",
      "Epoch 30/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0939 - accuracy: 0.9741\n",
      "Epoch 31/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.1016 - accuracy: 0.9743\n",
      "Epoch 32/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0964 - accuracy: 0.9750\n",
      "Epoch 33/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0934 - accuracy: 0.9757\n",
      "Epoch 34/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0943 - accuracy: 0.9752\n",
      "Epoch 35/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0937 - accuracy: 0.9755\n",
      "Epoch 36/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0939 - accuracy: 0.9757\n",
      "Epoch 37/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0962 - accuracy: 0.9750\n",
      "Epoch 38/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0891 - accuracy: 0.9761\n",
      "Epoch 39/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0924 - accuracy: 0.9760\n",
      "Epoch 40/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0948 - accuracy: 0.9755\n",
      "Epoch 41/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0928 - accuracy: 0.9754\n",
      "Epoch 42/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0972 - accuracy: 0.9752\n",
      "Epoch 43/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0903 - accuracy: 0.9765\n",
      "Epoch 44/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0888 - accuracy: 0.9763\n",
      "Epoch 45/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0865 - accuracy: 0.9771\n",
      "Epoch 46/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0897 - accuracy: 0.9765\n",
      "Epoch 47/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0924 - accuracy: 0.9759\n",
      "Epoch 48/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0937 - accuracy: 0.9770\n",
      "Epoch 49/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0876 - accuracy: 0.9770\n",
      "Epoch 50/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0931 - accuracy: 0.9763\n",
      "Epoch 51/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0925 - accuracy: 0.9770\n",
      "Epoch 52/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0935 - accuracy: 0.9769\n",
      "Epoch 53/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0930 - accuracy: 0.9767\n",
      "Epoch 54/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0937 - accuracy: 0.9771\n",
      "Epoch 55/100\n",
      "2623/2623 [==============================] - 74s 28ms/step - loss: 0.0939 - accuracy: 0.9766\n",
      "Epoch 56/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0941 - accuracy: 0.9765\n",
      "Epoch 57/100\n",
      "2623/2623 [==============================] - 72s 28ms/step - loss: 0.0890 - accuracy: 0.9772\n",
      "Epoch 58/100\n",
      "2623/2623 [==============================] - 72s 28ms/step - loss: 0.0887 - accuracy: 0.9776\n",
      "Epoch 59/100\n",
      "2623/2623 [==============================] - 72s 28ms/step - loss: 0.0950 - accuracy: 0.9766\n",
      "Epoch 60/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0934 - accuracy: 0.9764\n",
      "Epoch 61/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0944 - accuracy: 0.9777\n",
      "Epoch 62/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0939 - accuracy: 0.9775\n",
      "Epoch 63/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0956 - accuracy: 0.9766\n",
      "Epoch 64/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0854 - accuracy: 0.9780\n",
      "Epoch 65/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0872 - accuracy: 0.9785\n",
      "Epoch 66/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0930 - accuracy: 0.9777\n",
      "Epoch 67/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0969 - accuracy: 0.9774\n",
      "Epoch 68/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0950 - accuracy: 0.9783\n",
      "Epoch 69/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0942 - accuracy: 0.9765\n",
      "Epoch 70/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0979 - accuracy: 0.9772\n",
      "Epoch 71/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0917 - accuracy: 0.9784\n",
      "Epoch 72/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0994 - accuracy: 0.9756\n",
      "Epoch 73/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0921 - accuracy: 0.9775\n",
      "Epoch 74/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0933 - accuracy: 0.9781\n",
      "Epoch 75/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0924 - accuracy: 0.9780\n",
      "Epoch 76/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0926 - accuracy: 0.9775\n",
      "Epoch 77/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0895 - accuracy: 0.9782\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0854 - accuracy: 0.9788\n",
      "Epoch 79/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0913 - accuracy: 0.9778\n",
      "Epoch 80/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0907 - accuracy: 0.9781\n",
      "Epoch 81/100\n",
      "2623/2623 [==============================] - 72s 28ms/step - loss: 0.0931 - accuracy: 0.9782\n",
      "Epoch 82/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0870 - accuracy: 0.9794\n",
      "Epoch 83/100\n",
      "2623/2623 [==============================] - 72s 28ms/step - loss: 0.0943 - accuracy: 0.9783\n",
      "Epoch 84/100\n",
      "2623/2623 [==============================] - 73s 28ms/step - loss: 0.0935 - accuracy: 0.9784\n",
      "Epoch 85/100\n",
      "2623/2623 [==============================] - 79s 30ms/step - loss: 0.0892 - accuracy: 0.9780\n",
      "Epoch 86/100\n",
      "2623/2623 [==============================] - 79s 30ms/step - loss: 0.0963 - accuracy: 0.9774\n",
      "Epoch 87/100\n",
      "2623/2623 [==============================] - 80s 31ms/step - loss: 0.0848 - accuracy: 0.9798\n",
      "Epoch 88/100\n",
      "2623/2623 [==============================] - 84s 32ms/step - loss: 0.0940 - accuracy: 0.9777\n",
      "Epoch 89/100\n",
      "2623/2623 [==============================] - 81s 31ms/step - loss: 0.0913 - accuracy: 0.9784\n",
      "Epoch 90/100\n",
      "2623/2623 [==============================] - 80s 30ms/step - loss: 0.0885 - accuracy: 0.9791\n",
      "Epoch 91/100\n",
      "2623/2623 [==============================] - 81s 31ms/step - loss: 0.1008 - accuracy: 0.9773\n",
      "Epoch 92/100\n",
      "2623/2623 [==============================] - 80s 31ms/step - loss: 0.0886 - accuracy: 0.9790\n",
      "Epoch 93/100\n",
      "2623/2623 [==============================] - 81s 31ms/step - loss: 0.0981 - accuracy: 0.9775\n",
      "Epoch 94/100\n",
      "2623/2623 [==============================] - 81s 31ms/step - loss: 0.0926 - accuracy: 0.9783\n",
      "Epoch 95/100\n",
      "2623/2623 [==============================] - 80s 31ms/step - loss: 0.0890 - accuracy: 0.9794\n",
      "Epoch 96/100\n",
      "2623/2623 [==============================] - 93s 35ms/step - loss: 0.0892 - accuracy: 0.9790\n",
      "Epoch 97/100\n",
      "2623/2623 [==============================] - 80s 30ms/step - loss: 0.0938 - accuracy: 0.9777\n",
      "Epoch 98/100\n",
      "2623/2623 [==============================] - 80s 30ms/step - loss: 0.0909 - accuracy: 0.9785\n",
      "Epoch 99/100\n",
      "2623/2623 [==============================] - 88s 34ms/step - loss: 0.0950 - accuracy: 0.9780\n",
      "Epoch 100/100\n",
      "2623/2623 [==============================] - 84s 32ms/step - loss: 0.0968 - accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a39efc438>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = fetch_dataset('dataset_a1_f1_slim.pkl')\n",
    "data_train = make_tf_dataset(dataset, window_size, num_of_features, label_length ).batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "model.fit(data_train, epochs=ep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_a1_f1_{0}.h5'.format(ep))  # creates a HDF5 file 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    725/Unknown - 7s 9ms/step - loss: 0.6802 - accuracy: 0.8719"
     ]
    }
   ],
   "source": [
    "dataset = fetch_dataset('dataset_g1_slim.pkl')\n",
    "data_test = make_tf_dataset(dataset, window_size, num_of_features, label_length ).batch(batch_size)\n",
    "results = model.evaluate(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3008/3008 [==============================] - 110s 36ms/step - loss: 0.5358 - accuracy: 0.9143\n",
      "Epoch 2/100\n",
      "3008/3008 [==============================] - 107s 36ms/step - loss: 0.2218 - accuracy: 0.9468\n",
      "Epoch 3/100\n",
      "3008/3008 [==============================] - 98s 33ms/step - loss: 0.1800 - accuracy: 0.9538\n",
      "Epoch 4/100\n",
      "3008/3008 [==============================] - 122s 41ms/step - loss: 0.1741 - accuracy: 0.9580\n",
      "Epoch 5/100\n",
      "3008/3008 [==============================] - 102s 34ms/step - loss: 0.1584 - accuracy: 0.9601\n",
      "Epoch 6/100\n",
      "3008/3008 [==============================] - 100s 33ms/step - loss: 0.1601 - accuracy: 0.9617\n",
      "Epoch 7/100\n",
      "3008/3008 [==============================] - 97s 32ms/step - loss: 0.1467 - accuracy: 0.9636\n",
      "Epoch 8/100\n",
      "3008/3008 [==============================] - 104s 35ms/step - loss: 0.1463 - accuracy: 0.9637\n",
      "Epoch 9/100\n",
      "3008/3008 [==============================] - 97s 32ms/step - loss: 0.1353 - accuracy: 0.9654\n",
      "Epoch 10/100\n",
      "3008/3008 [==============================] - 108s 36ms/step - loss: 0.1406 - accuracy: 0.9655\n",
      "Epoch 11/100\n",
      "3008/3008 [==============================] - 96s 32ms/step - loss: 0.1398 - accuracy: 0.9668\n",
      "Epoch 12/100\n",
      "3008/3008 [==============================] - 106s 35ms/step - loss: 0.1278 - accuracy: 0.9678\n",
      "Epoch 13/100\n",
      "3008/3008 [==============================] - 111s 37ms/step - loss: 0.1248 - accuracy: 0.9683\n",
      "Epoch 14/100\n",
      "3008/3008 [==============================] - 101s 33ms/step - loss: 0.1334 - accuracy: 0.9678\n",
      "Epoch 15/100\n",
      "3008/3008 [==============================] - 101s 34ms/step - loss: 0.1359 - accuracy: 0.9686\n",
      "Epoch 16/100\n",
      "3008/3008 [==============================] - 104s 35ms/step - loss: 0.1336 - accuracy: 0.9680\n",
      "Epoch 17/100\n",
      "3008/3008 [==============================] - 106s 35ms/step - loss: 0.1280 - accuracy: 0.9700\n",
      "Epoch 18/100\n",
      "3008/3008 [==============================] - 114s 38ms/step - loss: 0.1257 - accuracy: 0.9696\n",
      "Epoch 19/100\n",
      "3008/3008 [==============================] - 106s 35ms/step - loss: 0.1269 - accuracy: 0.9701\n",
      "Epoch 20/100\n",
      "3008/3008 [==============================] - 99s 33ms/step - loss: 0.1249 - accuracy: 0.9706\n",
      "Epoch 21/100\n",
      "3008/3008 [==============================] - 99s 33ms/step - loss: 0.1239 - accuracy: 0.9712\n",
      "Epoch 22/100\n",
      "3008/3008 [==============================] - 104s 35ms/step - loss: 0.1221 - accuracy: 0.9711\n",
      "Epoch 23/100\n",
      "3008/3008 [==============================] - 97s 32ms/step - loss: 0.1230 - accuracy: 0.9713\n",
      "Epoch 24/100\n",
      "3008/3008 [==============================] - 100s 33ms/step - loss: 0.1237 - accuracy: 0.9709\n",
      "Epoch 25/100\n",
      "3008/3008 [==============================] - 104s 34ms/step - loss: 0.1200 - accuracy: 0.9720\n",
      "Epoch 26/100\n",
      "3008/3008 [==============================] - 108s 36ms/step - loss: 0.1182 - accuracy: 0.9722\n",
      "Epoch 27/100\n",
      "3008/3008 [==============================] - 112s 37ms/step - loss: 0.1301 - accuracy: 0.9709\n",
      "Epoch 28/100\n",
      "3008/3008 [==============================] - 115s 38ms/step - loss: 0.1178 - accuracy: 0.9721\n",
      "Epoch 29/100\n",
      "3008/3008 [==============================] - 166s 55ms/step - loss: 0.1220 - accuracy: 0.9721\n",
      "Epoch 30/100\n",
      "3008/3008 [==============================] - 103s 34ms/step - loss: 0.1144 - accuracy: 0.9724\n",
      "Epoch 31/100\n",
      "3008/3008 [==============================] - 114s 38ms/step - loss: 0.1202 - accuracy: 0.9728\n",
      "Epoch 32/100\n",
      "3008/3008 [==============================] - 139s 46ms/step - loss: 0.1236 - accuracy: 0.9728\n",
      "Epoch 33/100\n",
      "3008/3008 [==============================] - 196s 65ms/step - loss: 0.1244 - accuracy: 0.9721\n",
      "Epoch 34/100\n",
      "3008/3008 [==============================] - 152s 51ms/step - loss: 0.1265 - accuracy: 0.9730\n",
      "Epoch 35/100\n",
      "3008/3008 [==============================] - 139s 46ms/step - loss: 0.1238 - accuracy: 0.9727\n",
      "Epoch 36/100\n",
      "3008/3008 [==============================] - 152s 50ms/step - loss: 0.1155 - accuracy: 0.9730\n",
      "Epoch 37/100\n",
      "3008/3008 [==============================] - 138s 46ms/step - loss: 0.1213 - accuracy: 0.9729\n",
      "Epoch 38/100\n",
      "3008/3008 [==============================] - 112s 37ms/step - loss: 0.1167 - accuracy: 0.9723\n",
      "Epoch 39/100\n",
      "3008/3008 [==============================] - 99s 33ms/step - loss: 0.1156 - accuracy: 0.9727\n",
      "Epoch 40/100\n",
      "3008/3008 [==============================] - 93s 31ms/step - loss: 0.1252 - accuracy: 0.9721\n",
      "Epoch 41/100\n",
      "3008/3008 [==============================] - 96s 32ms/step - loss: 0.1273 - accuracy: 0.9723\n",
      "Epoch 42/100\n",
      "3008/3008 [==============================] - 115s 38ms/step - loss: 0.1229 - accuracy: 0.9727\n",
      "Epoch 43/100\n",
      "3008/3008 [==============================] - 138s 46ms/step - loss: 0.1136 - accuracy: 0.9737\n",
      "Epoch 44/100\n",
      "3008/3008 [==============================] - 119s 40ms/step - loss: 0.1105 - accuracy: 0.9741\n",
      "Epoch 45/100\n",
      "3008/3008 [==============================] - 112s 37ms/step - loss: 0.1191 - accuracy: 0.9736\n",
      "Epoch 46/100\n",
      "3008/3008 [==============================] - 115s 38ms/step - loss: 0.1152 - accuracy: 0.9734\n",
      "Epoch 47/100\n",
      "3008/3008 [==============================] - 104s 35ms/step - loss: 0.1233 - accuracy: 0.9731\n",
      "Epoch 48/100\n",
      "3008/3008 [==============================] - 123s 41ms/step - loss: 0.1168 - accuracy: 0.9732\n",
      "Epoch 49/100\n",
      "3008/3008 [==============================] - 118s 39ms/step - loss: 0.1216 - accuracy: 0.9736\n",
      "Epoch 50/100\n",
      "3008/3008 [==============================] - 104s 34ms/step - loss: 0.1202 - accuracy: 0.9728\n",
      "Epoch 51/100\n",
      "3008/3008 [==============================] - 115s 38ms/step - loss: 0.1231 - accuracy: 0.9733\n",
      "Epoch 52/100\n",
      "3008/3008 [==============================] - 127s 42ms/step - loss: 0.1287 - accuracy: 0.9733\n",
      "Epoch 53/100\n",
      "3008/3008 [==============================] - 113s 38ms/step - loss: 0.1217 - accuracy: 0.9734\n",
      "Epoch 54/100\n",
      "3008/3008 [==============================] - 105s 35ms/step - loss: 0.1207 - accuracy: 0.9728\n",
      "Epoch 55/100\n",
      "3008/3008 [==============================] - 102s 34ms/step - loss: 0.1227 - accuracy: 0.9734\n",
      "Epoch 56/100\n",
      "3008/3008 [==============================] - 101s 34ms/step - loss: 0.1213 - accuracy: 0.9734\n",
      "Epoch 57/100\n",
      "3008/3008 [==============================] - 112s 37ms/step - loss: 0.1180 - accuracy: 0.9732\n",
      "Epoch 58/100\n",
      "3008/3008 [==============================] - 110s 37ms/step - loss: 0.1254 - accuracy: 0.9726\n",
      "Epoch 59/100\n",
      "3008/3008 [==============================] - 102s 34ms/step - loss: 0.1206 - accuracy: 0.9739\n",
      "Epoch 60/100\n",
      "3008/3008 [==============================] - 103s 34ms/step - loss: 0.1161 - accuracy: 0.9746\n",
      "Epoch 61/100\n",
      "3008/3008 [==============================] - 99s 33ms/step - loss: 0.1183 - accuracy: 0.9733\n",
      "Epoch 62/100\n",
      "3008/3008 [==============================] - 99s 33ms/step - loss: 0.1126 - accuracy: 0.9755\n",
      "Epoch 63/100\n",
      "3008/3008 [==============================] - 87s 29ms/step - loss: 0.1264 - accuracy: 0.9738\n",
      "Epoch 64/100\n",
      "3008/3008 [==============================] - 86s 29ms/step - loss: 0.1218 - accuracy: 0.9733\n",
      "Epoch 65/100\n",
      "3008/3008 [==============================] - 109s 36ms/step - loss: 0.1171 - accuracy: 0.9736\n",
      "Epoch 66/100\n",
      "3008/3008 [==============================] - 91s 30ms/step - loss: 0.1159 - accuracy: 0.9741\n",
      "Epoch 67/100\n",
      "3008/3008 [==============================] - 94s 31ms/step - loss: 0.1159 - accuracy: 0.9749\n",
      "Epoch 68/100\n",
      "3008/3008 [==============================] - 90s 30ms/step - loss: 0.1131 - accuracy: 0.9751\n",
      "Epoch 69/100\n",
      "3008/3008 [==============================] - 96s 32ms/step - loss: 0.1179 - accuracy: 0.9747\n",
      "Epoch 70/100\n",
      "3008/3008 [==============================] - 102s 34ms/step - loss: 0.1203 - accuracy: 0.9747\n",
      "Epoch 71/100\n",
      "3008/3008 [==============================] - 114s 38ms/step - loss: 0.1261 - accuracy: 0.9733\n",
      "Epoch 72/100\n",
      "3008/3008 [==============================] - 135s 45ms/step - loss: 0.1219 - accuracy: 0.9734\n",
      "Epoch 73/100\n",
      "3008/3008 [==============================] - 118s 39ms/step - loss: 0.1164 - accuracy: 0.9745\n",
      "Epoch 74/100\n",
      "3008/3008 [==============================] - 99s 33ms/step - loss: 0.1238 - accuracy: 0.9736\n",
      "Epoch 75/100\n",
      "3008/3008 [==============================] - 96s 32ms/step - loss: 0.1192 - accuracy: 0.9747\n",
      "Epoch 76/100\n",
      "3008/3008 [==============================] - 96s 32ms/step - loss: 0.1220 - accuracy: 0.9736\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3008/3008 [==============================] - 92s 31ms/step - loss: 0.1201 - accuracy: 0.9750\n",
      "Epoch 78/100\n",
      "3008/3008 [==============================] - 93s 31ms/step - loss: 0.1221 - accuracy: 0.9744\n",
      "Epoch 79/100\n",
      "3008/3008 [==============================] - 92s 31ms/step - loss: 0.1220 - accuracy: 0.9731\n",
      "Epoch 80/100\n",
      "3008/3008 [==============================] - 94s 31ms/step - loss: 0.1146 - accuracy: 0.9750\n",
      "Epoch 81/100\n",
      "3008/3008 [==============================] - 88s 29ms/step - loss: 0.1176 - accuracy: 0.9759\n",
      "Epoch 82/100\n",
      "3008/3008 [==============================] - 89s 30ms/step - loss: 0.1114 - accuracy: 0.9746\n",
      "Epoch 83/100\n",
      "3008/3008 [==============================] - 107s 36ms/step - loss: 0.1096 - accuracy: 0.9762\n",
      "Epoch 84/100\n",
      "3008/3008 [==============================] - 105s 35ms/step - loss: 0.1123 - accuracy: 0.9750\n",
      "Epoch 85/100\n",
      "3008/3008 [==============================] - 113s 38ms/step - loss: 0.1205 - accuracy: 0.9734\n",
      "Epoch 86/100\n",
      "3008/3008 [==============================] - 117s 39ms/step - loss: 0.1130 - accuracy: 0.9745\n",
      "Epoch 87/100\n",
      "3008/3008 [==============================] - 112s 37ms/step - loss: 0.1103 - accuracy: 0.9753\n",
      "Epoch 88/100\n",
      "3008/3008 [==============================] - 110s 37ms/step - loss: 0.1108 - accuracy: 0.9755\n",
      "Epoch 89/100\n",
      "3008/3008 [==============================] - 118s 39ms/step - loss: 0.1149 - accuracy: 0.9750\n",
      "Epoch 90/100\n",
      "3008/3008 [==============================] - 115s 38ms/step - loss: 0.1151 - accuracy: 0.9751\n",
      "Epoch 91/100\n",
      "3008/3008 [==============================] - 98s 33ms/step - loss: 0.1209 - accuracy: 0.9746\n",
      "Epoch 92/100\n",
      "3008/3008 [==============================] - 106s 35ms/step - loss: 0.1188 - accuracy: 0.9746\n",
      "Epoch 93/100\n",
      "3008/3008 [==============================] - 129s 43ms/step - loss: 0.1148 - accuracy: 0.9750\n",
      "Epoch 94/100\n",
      "3008/3008 [==============================] - 137s 46ms/step - loss: 0.1118 - accuracy: 0.9748\n",
      "Epoch 95/100\n",
      "3008/3008 [==============================] - 121s 40ms/step - loss: 0.1243 - accuracy: 0.9741\n",
      "Epoch 96/100\n",
      "3008/3008 [==============================] - 119s 39ms/step - loss: 0.1207 - accuracy: 0.9733\n",
      "Epoch 97/100\n",
      "3008/3008 [==============================] - 125s 42ms/step - loss: 0.1144 - accuracy: 0.9755\n",
      "Epoch 98/100\n",
      "2962/3008 [============================>.] - ETA: 1s - loss: 0.1195 - accuracy: 0.9755"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-da7217a1341c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_f1_g1_{0}.h5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# creates a HDF5 file 'my_model.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;31m# Case 3: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1515\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1257\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3215\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3216\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3217\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3218\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n\u001b[1;32m   3219\u001b[0m                                  [x.numpy() for x in outputs])\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m    557\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m--> 558\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;31m# Only need to override the gradient in graph mode and when we have outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_register_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args)\u001b[0m\n\u001b[1;32m    413\u001b[0m             attrs=(\"executor_type\", executor_type,\n\u001b[1;32m    414\u001b[0m                    \"config_proto\", config),\n\u001b[0;32m--> 415\u001b[0;31m             ctx=ctx)\n\u001b[0m\u001b[1;32m    416\u001b[0m       \u001b[0;31m# Replace empty list with None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow-2.0.0a0-py3.7-macosx-10.7-x86_64.egg/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     59\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = fetch_dataset('dataset_f1_g1_slim.pkl')\n",
    "data_train = make_tf_dataset(dataset, window_size, num_of_features, label_length ).batch(batch_size)\n",
    "\n",
    "\n",
    "model.save('model_f1_g1_{0}.h5'.format(ep))  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "model.fit(data_train, epochs=ep)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2283/Unknown - 19s 9ms/step - loss: 2.2402 - accuracy: 0.8191"
     ]
    }
   ],
   "source": [
    "dataset = fetch_dataset('dataset_f1_slim.pkl')\n",
    "data_test = make_tf_dataset(dataset, window_size, num_of_features, label_length ).batch(batch_size)\n",
    "results = model.evaluate(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
